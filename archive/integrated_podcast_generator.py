#!/usr/bin/env python3
"""
Integrated Podcast Generator
æ•´åˆå·¥ä½œæµï¼šPodcastfy ç”Ÿæˆè…³æœ¬ + Gemini Multi-Speaker TTS ç”ŸæˆéŸ³é »
æ”¯æ´å¤šæ¨¡æ…‹è¼¸å…¥ï¼ˆæ–‡æª”ã€PDFã€ç¶²é ã€YouTubeï¼‰
"""

import os
import sys
import wave
import json
import yaml
import logging
import tempfile
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, Union
from dataclasses import dataclass
from urllib.parse import urlparse

# Performance tracking
from performance_tracker import (
    PerformanceTracker, 
    PerformanceReport, 
    time_stage,
    create_performance_tracker
)

# Google Gemini imports
try:
    from google import genai
    from google.genai import types
except ImportError:
    print("âŒ éœ€è¦å®‰è£ google-genai å¥—ä»¶")
    print("è«‹åŸ·è¡Œ: pip install google-genai")
    sys.exit(1)

# Podcastfy imports
try:
    from podcastfy.client import generate_podcast
except ImportError:
    print("âŒ éœ€è¦å®‰è£ podcastfy å¥—ä»¶")
    print("è«‹åŸ·è¡Œ: pip install podcastfy")
    sys.exit(1)

from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Check API keys
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
if not GEMINI_API_KEY:
    print("âŒ è«‹è¨­ç½® GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
    sys.exit(1)


@dataclass
class IntegratedPodcastConfig:
    """æ•´åˆæ’­å®¢é…ç½®"""
    input_source: str  # æ–‡ä»¶è·¯å¾‘ã€URLã€YouTube é€£çµç­‰
    input_type: str = "auto"  # 'text', 'pdf', 'url', 'youtube', 'auto'
    english_level: str = "B2"
    target_minutes: int = 1
    host_voice: str = "Kore"  # Gemini TTS ä¸»æŒäººèªéŸ³
    expert_voice: str = "Puck"  # Gemini TTS å°ˆå®¶èªéŸ³
    style_instructions: str = "conversational, engaging, educational"
    output_dir: str = "./integrated_output"
    use_podcastfy_tts: bool = False  # æ˜¯å¦ä½¿ç”¨ Podcastfy çš„ TTSï¼ˆå¦å‰‡ç”¨ Geminiï¼‰
    llm_model: str = "gemini-2.5-flash"  # LLM æ¨¡å‹åç¨±


class IntegratedPodcastGenerator:
    """æ•´åˆå¼æ’­å®¢ç”Ÿæˆå™¨"""
    
    def __init__(self, enable_performance_tracking: bool = True):
        self.gemini_client = genai.Client(api_key=GEMINI_API_KEY)
        self.supported_input_types = ['text', 'pdf', 'url', 'youtube']
        self.performance_tracker: Optional[PerformanceTracker] = None
        self.enable_performance_tracking = enable_performance_tracking
    
    @classmethod
    def from_config_file(cls, config_path: str = "./podcast_config.yaml"):
        """å¾é…ç½®æ–‡ä»¶å‰µå»ºæ’­å®¢ç”Ÿæˆå™¨"""
        return cls(), cls.load_config(config_path)
    
    @staticmethod
    def load_config(config_path: str = "./podcast_config.yaml") -> IntegratedPodcastConfig:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        config_file = Path(config_path)
        
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        
        return IntegratedPodcastConfig(
            input_source=config_data['input']['source'],
            input_type=config_data['input']['type'],
            english_level=config_data['basic']['english_level'],
            target_minutes=config_data['basic']['target_minutes'],
            host_voice=config_data['voices']['host_voice'],
            expert_voice=config_data['voices']['expert_voice'],
            style_instructions=config_data['basic']['style_instructions'],
            output_dir=config_data['advanced']['output_dir'],
            use_podcastfy_tts=config_data['advanced']['use_podcastfy_tts'],
            llm_model=config_data['advanced']['llm_model']
        )
        
    @time_stage("è¼¸å…¥é¡å‹æª¢æ¸¬")
    def detect_input_type(self, input_source: str) -> str:
        """è‡ªå‹•æª¢æ¸¬è¼¸å…¥é¡å‹"""
        # æª¢æŸ¥æ˜¯å¦ç‚º URL
        if input_source.startswith(('http://', 'https://')):
            if 'youtube.com' in input_source or 'youtu.be' in input_source:
                return 'youtube'
            return 'url'
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæª”æ¡ˆ
        if Path(input_source).exists():
            suffix = Path(input_source).suffix.lower()
            if suffix == '.pdf':
                return 'pdf'
            elif suffix in ['.txt', '.md']:
                return 'text'
        
        # é è¨­ç‚ºæ–‡æœ¬å…§å®¹
        return 'text'
    
    def calculate_length_parameters(self, target_minutes: int) -> dict:
        """åŸºæ–¼ Podcastfy ç¤¾å€æœ€ä½³å¯¦è¸çš„é•·åº¦æ§åˆ¶åƒæ•¸"""
        # åŸºæ–¼ç¤¾å€é©—è­‰çš„é…ç½®æ¨¡å¼ï¼Œä¾†è‡ªå®˜æ–¹æ–‡æª”å’Œç”¨æˆ¶å¯¦è¸
        # ç¤¾å€ç™¼ç¾ï¼šmin_chunk_size è‡³å°‘ 600 æ‰èƒ½ä¿è­‰å°è©±è³ªé‡
        # word_count æ˜¯å½ˆæ€§å»ºè­°ï¼Œä¸æ˜¯åš´æ ¼é™åˆ¶
        
        community_best_practices = {
            0.5: {
                "word_count": 200,           # ç¤¾å€ shortform ä¸‹é™
                "max_num_chunks": 3,         # ç°¡çŸ­ä¸”é›†ä¸­
                "min_chunk_size": 600,       # ç¤¾å€æœ€ä½è³ªé‡æ¨™æº–
                "conversation_style": ["concise", "focused"]
            },
            1: {
                "word_count": 300,           # ç¤¾å€å»ºè­°ç¯„åœ
                "max_num_chunks": 4,         # é©åº¦è¨è«–è¼ªæ¬¡
                "min_chunk_size": 600,       # ä¿è­‰å°è©±å®Œæ•´æ€§
                "conversation_style": ["concise", "engaging"]
            },
            2: {
                "word_count": 600,           # æ¥è¿‘ç¤¾å€ shortform æ¨™æº–
                "max_num_chunks": 5,         # å¹³è¡¡è¨è«–æ·±åº¦
                "min_chunk_size": 600,       # ç¶­æŒè³ªé‡é–€æª»
                "conversation_style": ["engaging", "informative"]
            },
            3: {
                "word_count": 800,           # ç¤¾å€æ•™è‚²å…§å®¹æ¨™æº–
                "max_num_chunks": 6,         # ç¤¾å€æ¨è–¦ç¯„åœ
                "min_chunk_size": 600,       # ç¢ºä¿å°è©±è³ªé‡
                "conversation_style": ["engaging", "educational"]
            },
            5: {
                "word_count": 1200,          # åƒè€ƒç¤¾å€è©³ç´°è¨è«–æ¡ˆä¾‹
                "max_num_chunks": 8,         # å…è¨±æ›´å¤šè¼ªæ¬¡
                "min_chunk_size": 700,       # æå‡å…§å®¹æ·±åº¦
                "conversation_style": ["detailed", "comprehensive"]
            },
            10: {
                "word_count": 2000,          # ç¤¾å€é•·å½¢å¼ä¸‹é™
                "max_num_chunks": 12,        # æ¥è¿‘ç¤¾å€é è¨­ä¸Šé™
                "min_chunk_size": 800,       # ç¢ºä¿æ·±åº¦è¨è«–
                "conversation_style": ["in-depth", "analytical"]
            },
            15: {
                "word_count": 3000,          # ç¤¾å€å­¸è¡“è¨è«–æ¨™æº–
                "max_num_chunks": 15,        # å……åˆ†è¨è«–ç©ºé–“
                "min_chunk_size": 800,       # é«˜è³ªé‡å…§å®¹å¡Š
                "conversation_style": ["academic", "comprehensive"]
            },
            20: {
                "word_count": 4000,          # ç¤¾å€é•·å½¢å¼æ¨™æº–
                "max_num_chunks": 18,        # è±å¯Œè¨è«–è¼ªæ¬¡
                "min_chunk_size": 900,       # æœ€é«˜è³ªé‡è¦æ±‚
                "conversation_style": ["detailed", "thorough"]
            }
        }
        
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„ç¤¾å€å¯¦è¸é…ç½®
        closest_time = min(community_best_practices.keys(), 
                          key=lambda x: abs(x - target_minutes))
        config = community_best_practices[closest_time].copy()
        
        # å°æ–¼è¶…å‡ºç¯„åœçš„æ™‚é•·ï¼ŒåŸºæ–¼ç¤¾å€æœ€ä½³å¯¦è¸å¤–æ¨
        if target_minutes > max(community_best_practices.keys()):
            # ç¤¾å€ç¶“é©—ï¼šé•·å½¢å¼æ’­å®¢çš„åˆç†ä¸Šé™å’Œè³ªé‡ä¿è­‰
            config = {
                "word_count": min(target_minutes * 200, 8000),  # é¿å…éé•·å½±éŸ¿è³ªé‡
                "max_num_chunks": min(target_minutes, 25),      # ç¤¾å€å¯¦è¸ä¸Šé™
                "min_chunk_size": 900,                          # æœ€é«˜è³ªé‡æ¨™æº–
                "conversation_style": ["comprehensive", "detailed"]
            }
        
        logger.info(f"ğŸ“‹ ç¤¾å€æœ€ä½³å¯¦è¸é…ç½® ({target_minutes}åˆ†é˜): "
                   f"å­—æ•¸={config['word_count']}, è¼ªæ¬¡={config['max_num_chunks']}, "
                   f"æœ€å°å¡Š={config['min_chunk_size']}, é¢¨æ ¼={config['conversation_style']}")
        
        return config
    
    def _generate_smart_instructions(self, config: IntegratedPodcastConfig, length_params: dict) -> str:
        """åŸºæ–¼ç¤¾å€æœ€ä½³å¯¦è¸ç”Ÿæˆæ™ºèƒ½æŒ‡å°æŒ‡ä»¤"""
        target_minutes = config.target_minutes
        style_mix = ", ".join(length_params["conversation_style"])
        
        # åŸºæ–¼ç¤¾å€ç¶“é©—çš„æ™‚é•·æŒ‡å°ç­–ç•¥
        if target_minutes <= 1:
            content_guidance = """Create a focused, high-level overview that delivers key insights efficiently.
            Keep discussions concise and impactful. Prioritize the most important points."""
            
        elif target_minutes <= 3:
            content_guidance = """Create an engaging educational discussion with moderate depth.
            Balance accessibility with substantial content. Focus on clear explanations and practical insights."""
            
        elif target_minutes <= 5:
            content_guidance = """Create a comprehensive exploration that balances breadth and depth.
            Allow for detailed explanations while maintaining listener engagement throughout."""
            
        else:
            content_guidance = """Create an in-depth, thorough analysis with comprehensive coverage.
            Allow for detailed explanations, examples, and nuanced discussion of complex topics."""
        
        # ç¤¾å€æ¨è–¦çš„è‡ªç„¶çµæ§‹æŒ‡å°
        structure_guidance = f"""
        CONVERSATION STRUCTURE (ç¤¾å€æœ€ä½³å¯¦è¸):
        1. OPENING: Natural welcome and topic introduction
        2. MAIN DISCUSSION: {style_mix} exploration of the content
        3. CLOSING: Natural conclusion when discussion feels complete
        
        QUALITY GUIDELINES:
        - Use appropriate vocabulary for {config.english_level} English learners
        - Style: {config.style_instructions}
        - Maintain natural conversation flow between Host and Expert
        - Host guides with thoughtful questions, Expert provides insights
        - Let the conversation develop organically within the style parameters
        
        ENDING GUIDANCE:
        - Conclude naturally when key points are covered
        - Use natural closing phrases like "That wraps up", "To summarize", "Thanks for this discussion"
        - Trust the conversation flow rather than forcing artificial limits
        """
        
        return f"""
        Create a podcast conversation for {config.english_level} English learners.
        
        CONTENT APPROACH:
        {content_guidance}
        
        {structure_guidance}
        
        Remember: Focus on delivering value and maintaining conversation quality. 
        The goal is a natural, {style_mix} discussion that serves {config.english_level} learners well.
        """
    
    def save_wave_file(self, filename: str, pcm_data: bytes, channels: int = 1, rate: int = 24000, sample_width: int = 2):
        """ä¿å­˜ WAV éŸ³é »æª”æ¡ˆ"""
        with wave.open(filename, "wb") as wf:
            wf.setnchannels(channels)
            wf.setsampwidth(sample_width)
            wf.setframerate(rate)
            wf.writeframes(pcm_data)
    
    @time_stage("Podcastfy è…³æœ¬ç”Ÿæˆ")
    def generate_script_with_podcastfy(self, config: IntegratedPodcastConfig) -> Dict[str, Any]:
        """ä½¿ç”¨ Podcastfy ç”Ÿæˆå°è©±è…³æœ¬"""
        logger.info("ğŸ“ ä½¿ç”¨ Podcastfy ç”Ÿæˆå°è©±è…³æœ¬...")
        
        # è‡ªå‹•æª¢æ¸¬è¼¸å…¥é¡å‹
        if config.input_type == "auto":
            config.input_type = self.detect_input_type(config.input_source)
            logger.info(f"æª¢æ¸¬åˆ°è¼¸å…¥é¡å‹: {config.input_type}")
        
        # æ ¹æ“šæ™‚é•·è¨ˆç®—ç²¾ç¢ºçš„é•·åº¦æ§åˆ¶åƒæ•¸
        length_params = self.calculate_length_parameters(config.target_minutes)
        
        # æº–å‚™ Podcastfy é…ç½®ï¼ˆåŸºæ–¼ç¤¾å€æœ€ä½³å¯¦è¸ï¼‰
        conversation_config = {
            "word_count": length_params["word_count"],
            "max_num_chunks": length_params["max_num_chunks"],
            "min_chunk_size": length_params["min_chunk_size"],
            "conversation_style": length_params["conversation_style"],  # ä½¿ç”¨ç¤¾å€æ¨è–¦çš„é¢¨æ ¼çµ„åˆ
            "language": "English",
            "dialogue_structure": "two_speakers",
            "custom_instructions": self._generate_smart_instructions(config, length_params),
            "roles": ["Host", "Expert"],
            "output_folder": config.output_dir
        }
        
        # å‰µå»ºè‡¨æ™‚è¼¸å‡ºç›®éŒ„
        temp_dir = Path(config.output_dir) / f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        temp_dir.mkdir(parents=True, exist_ok=True)
        conversation_config["output_folder"] = str(temp_dir)
        
        try:
            # æ ¹æ“šè¼¸å…¥é¡å‹èª¿ç”¨ Podcastfy
            if config.input_type == 'text':
                # å¦‚æœæ˜¯æª”æ¡ˆè·¯å¾‘ï¼Œè®€å–å…§å®¹
                if Path(config.input_source).exists():
                    with open(config.input_source, 'r', encoding='utf-8') as f:
                        content = f.read()
                else:
                    content = config.input_source
                
                result = generate_podcast(
                    text=content,
                    llm_model_name=config.llm_model,
                    api_key_label="GEMINI_API_KEY",
                    conversation_config=conversation_config,
                    transcript_only=not config.use_podcastfy_tts  # True = åªç”Ÿæˆè…³æœ¬ï¼Œçµ¦ Gemini TTS ä½¿ç”¨
                )
                
            elif config.input_type == 'pdf':
                result = generate_podcast(
                    pdf_file_path=config.input_source,
                    llm_model_name=config.llm_model,
                    api_key_label="GEMINI_API_KEY",
                    conversation_config=conversation_config,
                    transcript_only=not config.use_podcastfy_tts
                )
                
            elif config.input_type == 'url':
                result = generate_podcast(
                    urls=[config.input_source],
                    llm_model_name=config.llm_model,
                    api_key_label="GEMINI_API_KEY",
                    conversation_config=conversation_config,
                    transcript_only=not config.use_podcastfy_tts
                )
                
            elif config.input_type == 'youtube':
                result = generate_podcast(
                    youtube_urls=[config.input_source],
                    llm_model_name=config.llm_model,
                    api_key_label="GEMINI_API_KEY",
                    conversation_config=conversation_config,
                    transcript_only=not config.use_podcastfy_tts
                )
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„è¼¸å…¥é¡å‹: {config.input_type}")
            
            # å°‹æ‰¾ç”Ÿæˆçš„è…³æœ¬æª”æ¡ˆï¼ˆPodcastfy ä¿å­˜åœ¨ ./data/transcripts/ï¼‰
            data_transcript_dir = Path("./data/transcripts/")
            transcript_files = list(data_transcript_dir.glob("transcript*.txt"))
            if not transcript_files:
                # å‚™ç”¨ï¼šæœå°‹è‡¨æ™‚ç›®éŒ„
                transcript_files = list(temp_dir.glob("**/transcript*.txt"))
                if not transcript_files:
                    transcript_files = list(temp_dir.glob("**/*.txt"))
            
            if transcript_files:
                transcript_file = transcript_files[0]
                with open(transcript_file, 'r', encoding='utf-8') as f:
                    script = f.read()
                
                # ä¿¡ä»»ç¤¾å€æœ€ä½³å¯¦è¸ï¼šAI æœƒæ ¹æ“šé…ç½®è‡ªç„¶ç”Ÿæˆé©ç•¶é•·åº¦çš„å…§å®¹
                
                logger.info(f"âœ… è…³æœ¬ç”Ÿæˆå®Œæˆï¼ˆ{len(script.split())} wordsï¼‰")
                
                # å¦‚æœä½¿ç”¨ Podcastfy çš„ TTSï¼ŒæŸ¥æ‰¾éŸ³é »æª”æ¡ˆ
                if config.use_podcastfy_tts:
                    data_audio_dir = Path("./data/audio/")
                    audio_files = list(data_audio_dir.glob("podcast*.mp3"))
                    if not audio_files:
                        audio_files = list(temp_dir.glob("**/*.mp3"))
                    
                    if audio_files:
                        return {
                            "status": "success",
                            "script": script,
                            "script_file": str(transcript_file),
                            "audio_file": str(audio_files[0]),
                            "used_podcastfy_tts": True
                        }
                
                return {
                    "status": "success",
                    "script": script,
                    "script_file": str(transcript_file)
                }
            else:
                raise Exception("æœªæ‰¾åˆ°ç”Ÿæˆçš„è…³æœ¬æª”æ¡ˆ")
                
        except Exception as e:
            logger.error(f"âŒ è…³æœ¬ç”Ÿæˆå¤±æ•—: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    @time_stage("Gemini TTS éŸ³é »ç”Ÿæˆ")
    def generate_audio_from_script(self, script: str, config: IntegratedPodcastConfig) -> bytes:
        """ä½¿ç”¨ Gemini Multi-Speaker TTS ç”ŸæˆéŸ³é »"""
        logger.info("ğŸµ ä½¿ç”¨ Gemini Multi-Speaker TTS ç”ŸæˆéŸ³é »...")
        
        # æº–å‚™ TTS æç¤º
        tts_prompt = f"""Say this conversation between Host and Expert with {config.style_instructions} tone:

{script}"""
        
        try:
            # ä½¿ç”¨æ­£ç¢ºçš„å¤šèªªè©±è€…é…ç½®ï¼ˆéœ€è¦ google-genai >= 1.31.0ï¼‰
            response = self.gemini_client.models.generate_content(
                model="gemini-2.5-flash-preview-tts",
                contents=tts_prompt,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(
                            speaker_voice_configs=[
                                types.SpeakerVoiceConfig(
                                    speaker="Person1",  # ä¸»æŒäºº
                                    voice_config=types.VoiceConfig(
                                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                            voice_name=config.host_voice
                                        )
                                    )
                                ),
                                types.SpeakerVoiceConfig(
                                    speaker="Person2",  # å°ˆå®¶
                                    voice_config=types.VoiceConfig(
                                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                            voice_name=config.expert_voice
                                        )
                                    )
                                )
                            ]
                        )
                    )
                )
            )
            
            # æå–éŸ³é »æ•¸æ“š
            audio_data = response.candidates[0].content.parts[0].inline_data.data
            logger.info(f"âœ… éŸ³é »ç”Ÿæˆå®Œæˆï¼ˆ{len(audio_data)/1024:.1f} KBï¼‰")
            return audio_data
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »ç”Ÿæˆå¤±æ•—: {e}")
            raise
    
    def generate(self, config: IntegratedPodcastConfig) -> Dict[str, Any]:
        """å®Œæ•´çš„æ•´åˆç”Ÿæˆæµç¨‹"""
        # åˆå§‹åŒ–æ€§èƒ½è¿½è¹¤
        if self.enable_performance_tracking:
            self.performance_tracker = create_performance_tracker()
            self.performance_tracker.start_session({
                "input_source": config.input_source,
                "input_type": config.input_type,
                "english_level": config.english_level,
                "target_minutes": config.target_minutes,
                "host_voice": config.host_voice,
                "expert_voice": config.expert_voice,
                "use_podcastfy_tts": config.use_podcastfy_tts
            })
        
        print("\n" + "=" * 60)
        print("ğŸš€ æ•´åˆå¼æ’­å®¢ç”Ÿæˆ")
        print(f"ğŸ“¥ è¼¸å…¥ä¾†æº: {config.input_source}")
        print(f"ğŸ¯ è‹±èªç­‰ç´š: {config.english_level}")
        print(f"â±ï¸ ç›®æ¨™é•·åº¦: {config.target_minutes} åˆ†é˜")
        if self.performance_tracker:
            print(f"ğŸ“Š æ€§èƒ½è¿½è¹¤: {self.performance_tracker.session_id}")
        print("=" * 60)
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        output_dir = Path(config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_dir = output_dir / f"podcast_{config.english_level}_{timestamp}"
        session_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # Step 1: ä½¿ç”¨ Podcastfy ç”Ÿæˆè…³æœ¬
            print("\nğŸ“ Step 1: ç”Ÿæˆå°è©±è…³æœ¬...")
            script_result = self.generate_script_with_podcastfy(config)
            
            if script_result["status"] != "success":
                raise Exception(f"è…³æœ¬ç”Ÿæˆå¤±æ•—: {script_result.get('error', 'Unknown error')}")
            
            script = script_result["script"]
            
            # ä¿å­˜è…³æœ¬
            script_file = session_dir / "script.txt"
            script_file.write_text(script, encoding='utf-8')
            print(f"ğŸ’¾ è…³æœ¬å·²ä¿å­˜: {script_file}")
            
            # å¦‚æœå·²ç¶“ä½¿ç”¨ Podcastfy TTSï¼Œç›´æ¥è¿”å›
            if script_result.get("used_podcastfy_tts"):
                print("âœ… ä½¿ç”¨ Podcastfy TTS å®Œæˆ")
                return {
                    "status": "success",
                    "output_dir": str(session_dir),
                    "script_file": str(script_file),
                    "audio_file": script_result["audio_file"],
                    "tts_provider": "podcastfy"
                }
            
            # Step 2: ä½¿ç”¨ Gemini TTS ç”ŸæˆéŸ³é »
            print("\nğŸµ Step 2: ç”ŸæˆéŸ³é »...")
            audio_data = self.generate_audio_from_script(script, config)
            
            # ä¿å­˜éŸ³é »
            audio_file = session_dir / "podcast.wav"
            self.save_wave_file(str(audio_file), audio_data)
            print(f"ğŸ’¾ éŸ³é »å·²ä¿å­˜: {audio_file}")
            
            # ä¿å­˜å…ƒæ•¸æ“š
            metadata = {
                "timestamp": timestamp,
                "input_source": config.input_source,
                "input_type": config.input_type,
                "english_level": config.english_level,
                "target_minutes": config.target_minutes,
                "host_voice": config.host_voice,
                "expert_voice": config.expert_voice,
                "script_words": len(script.split()),
                "audio_size_kb": len(audio_data) / 1024,
                "tts_provider": "gemini",
                "files": {
                    "script": str(script_file),
                    "audio": str(audio_file)
                }
            }
            
            metadata_file = session_dir / "metadata.json"
            metadata_file.write_text(json.dumps(metadata, indent=2), encoding='utf-8')
            
            print("\n" + "=" * 60)
            print("âœ… æ’­å®¢ç”ŸæˆæˆåŠŸï¼")
            print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {session_dir}")
            print(f"ğŸµ éŸ³é »æª”æ¡ˆ: {audio_file.name} ({len(audio_data)/1024:.1f} KB)")
            print(f"ğŸ“ è…³æœ¬æª”æ¡ˆ: {script_file.name} ({len(script.split())} words)")
            print("=" * 60)
            
            # å®Œæˆæ€§èƒ½è¿½è¹¤
            result = {
                "status": "success",
                "output_dir": str(session_dir),
                "audio_file": str(audio_file),
                "script_file": str(script_file),
                "metadata": metadata
            }
            
            if self.performance_tracker:
                # çµæŸæ€§èƒ½è¿½è¹¤æœƒè©±
                performance_metrics = self.performance_tracker.finish_session(
                    success=True,
                    output_files={
                        "audio": str(audio_file),
                        "script": str(script_file),
                        "metadata": str(metadata_file)
                    }
                )
                
                # ä¿å­˜æ€§èƒ½æŒ‡æ¨™
                try:
                    metrics_file = self.performance_tracker.save_metrics(str(session_dir))
                    result["performance_metrics_file"] = metrics_file
                except Exception as e:
                    logger.warning(f"âš ï¸ ä¿å­˜æ€§èƒ½æŒ‡æ¨™å¤±æ•—: {e}")
                
                # é¡¯ç¤ºæ€§èƒ½å ±å‘Š
                print("\n" + PerformanceReport.generate_console_report(self.performance_tracker))
            
            return result
            
        except Exception as e:
            print(f"\nâŒ æ’­å®¢ç”Ÿæˆå¤±æ•—: {e}")
            
            # åœ¨éŒ¯èª¤æƒ…æ³ä¸‹ä¹Ÿå®Œæˆæ€§èƒ½è¿½è¹¤
            result = {
                "status": "error",
                "error": str(e)
            }
            
            if self.performance_tracker:
                try:
                    self.performance_tracker.finish_session(success=False)
                    metrics_file = self.performance_tracker.save_metrics("./performance_logs")
                    result["performance_metrics_file"] = metrics_file
                    
                    # é¡¯ç¤ºéŒ¯èª¤æƒ…æ³ä¸‹çš„æ€§èƒ½å ±å‘Š
                    print("\n" + PerformanceReport.generate_console_report(self.performance_tracker))
                except Exception as tracking_error:
                    logger.warning(f"âš ï¸ æ€§èƒ½è¿½è¹¤éŒ¯èª¤: {tracking_error}")
            
            return result


def generate_from_config(config_path: str = "./podcast_config.yaml"):
    """å¾é…ç½®æ–‡ä»¶ç”Ÿæˆæ’­å®¢"""
    try:
        generator, config = IntegratedPodcastGenerator.from_config_file(config_path)
        return generator.generate(config)
    except Exception as e:
        print(f"âŒ é…ç½®è¼‰å…¥å¤±æ•—: {e}")
        return {"status": "error", "error": str(e)}


def test_multimodal_inputs():
    """æ¸¬è©¦ä¸åŒé¡å‹çš„è¼¸å…¥"""
    generator = IntegratedPodcastGenerator()
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        {
            "name": "å¾é…ç½®æ–‡ä»¶ç”Ÿæˆæ’­å®¢",
            "use_config": True
        },
        {
            "name": "æ–‡æœ¬æª”æ¡ˆæ¸¬è©¦ï¼ˆPodcastfy è…³æœ¬ + Gemini Multi-Speaker TTSï¼‰",
            "config": IntegratedPodcastConfig(
                input_source="./sample_article.txt",
                english_level="B2",
                target_minutes=1,
                style_instructions="educational and clear",
                use_podcastfy_tts=False  # Podcastfy åªåšè…³æœ¬ï¼ŒGemini Multi-Speaker TTS åšéŸ³é »
            )
        },
        # å¯ä»¥åŠ å…¥æ›´å¤šæ¸¬è©¦æ¡ˆä¾‹ï¼š
        # PDF: input_source="./document.pdf"
        # ç¶²é : input_source="https://example.com/article"
        # YouTube: input_source="https://youtube.com/watch?v=..."
    ]
    
    for test_case in test_cases:
        print(f"\nğŸ§ª {test_case['name']}")
        print("-" * 40)
        
        if test_case.get('use_config'):
            # ä½¿ç”¨é…ç½®æ–‡ä»¶
            result = generate_from_config()
        else:
            # æª¢æŸ¥è¼¸å…¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
            if test_case['config'].input_source.startswith('./'):
                if not Path(test_case['config'].input_source).exists():
                    # å‰µå»ºæ¸¬è©¦æª”æ¡ˆ
                    test_content = """
                    The Impact of Artificial Intelligence on Education
                    
                    Artificial Intelligence is revolutionizing education in unprecedented ways. 
                    From personalized learning paths to intelligent tutoring systems, AI helps 
                    students learn at their own pace. Teachers can use AI tools to identify 
                    learning gaps and provide targeted support. The technology also enables 
                    accessible education for students with disabilities, breaking down 
                    traditional barriers to learning.
                    
                    AI-powered adaptive learning platforms adjust difficulty levels based on 
                    student performance, ensuring optimal challenge and engagement. Virtual 
                    teaching assistants can answer questions 24/7, providing instant support. 
                    Automated grading systems free up teachers' time for more meaningful 
                    interactions with students.
                    """
                    
                    Path(test_case['config'].input_source).write_text(test_content)
                    print(f"å‰µå»ºæ¸¬è©¦æª”æ¡ˆ: {test_case['config'].input_source}")
            
            result = generator.generate(test_case['config'])
        
        if result["status"] == "success":
            print(f"âœ… æ¸¬è©¦æˆåŠŸ")
        else:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {result.get('error')}")
    
    return True


if __name__ == "__main__":
    print("ğŸ¯ æ•´åˆå¼æ’­å®¢ç”Ÿæˆå™¨")
    print("æ”¯æ´è¼¸å…¥æ ¼å¼ï¼šæ–‡æœ¬æª”æ¡ˆã€PDFã€ç¶²é ã€YouTube")
    print("=" * 60)
    
    # åŸ·è¡Œæ¸¬è©¦
    success = test_multimodal_inputs()
    
    if success:
        print("\nğŸ‰ æ¸¬è©¦å®Œæˆï¼")
        print("\nä½¿ç”¨æ–¹å¼ï¼š")
        print("1. æº–å‚™ä»»ä½•æ ¼å¼çš„å…§å®¹ï¼ˆæ–‡æœ¬ã€PDFã€ç¶²é ã€YouTubeï¼‰")
        print("2. è¨­å®šè‹±èªé›£åº¦ç­‰ç´šï¼ˆA1-C2ï¼‰")
        print("3. Podcastfy è‡ªå‹•ç”Ÿæˆå°è©±è…³æœ¬")
        print("4. Gemini Multi-Speaker TTS ç”Ÿæˆé«˜å“è³ªéŸ³é »")
    
    sys.exit(0 if success else 1)