#!/usr/bin/env python3
"""Generate condensed chapter summaries with Gemini 2.5 Flash."""

from __future__ import annotations

import argparse
import json
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from textwrap import dedent
from typing import Any, Dict, List, Tuple

import yaml
from dotenv import load_dotenv
from google import genai
from google.genai import types

load_dotenv()

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    print("âŒ è«‹å…ˆåœ¨ .env è¨­å®š GEMINI_API_KEY")
    sys.exit(1)


def load_config(config_path: str) -> Dict[str, Any]:
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def resolve_book_config(config: Dict[str, Any], book_id: str) -> Dict[str, Any]:
    paths_cfg = config.get("paths", {})
    books_root = Path(paths_cfg.get("books_root", "./data")).expanduser().resolve()
    if not book_id:
        raise ValueError("å¿…é ˆæŒ‡å®š --book-id æˆ–ç’°å¢ƒè®Šæ•¸ STORY_BOOK_ID")

    book_dir = books_root / book_id
    if not book_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ›¸ç±è³‡æ–™å¤¾: {book_dir}")

    books_cfg = config.get("books", {})
    defaults = books_cfg.get("defaults", {})
    overrides = (books_cfg.get("overrides", {}) or {}).get(book_id, {})

    merged = dict(defaults)
    merged.update(overrides)

    summary_subdir = merged.get("summary_subdir", "summaries")
    summary_suffix = merged.get("summary_suffix", "_summary.txt")

    merged["book_id"] = book_id
    merged["books_root"] = str(books_root)
    merged["chapters_dir"] = str(book_dir)
    merged["summary_subdir"] = summary_subdir
    merged["summary_suffix"] = summary_suffix
    merged["summaries_dir"] = str((book_dir / summary_subdir).resolve())

    return merged


def clean_text(content: str) -> str:
    lines = [line.rstrip() for line in content.splitlines()]
    cleaned: List[str] = []
    for line in lines:
        if not line.strip():
            if cleaned and cleaned[-1] != "":
                cleaned.append("")
            continue
        cleaned.append(line.strip())
    return "\n".join(cleaned).strip()


def natural_key(text: str) -> List[Any]:
    import re

    parts = re.split(r"(\d+)", text)
    key: List[Any] = []
    for part in parts:
        if part.isdigit():
            key.append(int(part))
        else:
            key.append(part.lower())
    return key


@dataclass
class ChapterFile:
    number: int
    path: Path
    word_count: int
    content: str


def collect_chapter_files(book_cfg: Dict[str, Any]) -> List[ChapterFile]:
    chapters_dir = Path(book_cfg['chapters_dir']).expanduser()
    if not chapters_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ›¸ç±è³‡æ–™å¤¾: {chapters_dir}")

    pattern = book_cfg.get('file_pattern', 'chapter*.txt')
    files = sorted(chapters_dir.glob(pattern), key=lambda p: natural_key(p.stem))
    if not files:
        raise ValueError(f"åœ¨ {chapters_dir} ä½¿ç”¨æ¨£å¼ '{pattern}' æœªæ‰¾åˆ°ä»»ä½•ç« ç¯€æª”æ¡ˆ")

    encoding = book_cfg.get('encoding', 'utf-8')
    clean_ws = book_cfg.get('clean_whitespace', True)
    min_words = book_cfg.get('min_words', 0)

    chapters: List[ChapterFile] = []
    skipped: List[str] = []
    for file_path in files:
        text = file_path.read_text(encoding=encoding)
        if clean_ws:
            text = clean_text(text)
        words = text.split()
        if len(words) < min_words:
            skipped.append(file_path.name)
            continue
        chapters.append(
            ChapterFile(
                number=len(chapters) + 1,
                path=file_path,
                word_count=len(words),
                content=text,
            )
        )

    if skipped:
        print(f"âš ï¸ ä»¥ä¸‹æª”æ¡ˆå› å­—æ•¸å°‘æ–¼ min_words={min_words} è¢«ç•¥é: {', '.join(skipped)}")
    if not chapters:
        raise ValueError("æ‰€æœ‰ç« ç¯€éƒ½è¢«ç•¥éï¼Œè«‹ç¢ºèªç« ç¯€æª”æ¡ˆå…§å®¹")
    return chapters


def extract_text(response) -> str:
    if hasattr(response, "text") and response.text:
        return response.text
    for candidate in getattr(response, "candidates", []) or []:
        content = getattr(candidate, "content", None)
        if not content:
            continue
        for part in getattr(content, "parts", []) or []:
            if hasattr(part, "text") and part.text:
                return part.text
    raise ValueError("å›æ‡‰ä¸­æ²’æœ‰æ–‡å­—å…§å®¹")


def summarize_chapter(client: genai.Client, model: str, chapter: ChapterFile,
                      target_words: int, temperature: float = 0.2) -> str:
    prompt = dedent(f"""
    You are preparing a condensed recap for an audio storytelling workflow.
    - Compress the chapter to roughly {target_words} words (~1/8 of the source length).
    - Preserve key plot beats, character motivations, and any foreshadowing hooks.
    - Use 2-3 short paragraphs written in present tense narrative voice.
    - End with one sentence that hints at what listeners should anticipate next if such hint exists.
    - Do not include bullet lists or chapter numbers.

    Source chapter:
    {chapter.content}
    """).strip()

    response = client.models.generate_content(
        model=model,
        contents=prompt,
        config=types.GenerateContentConfig(temperature=temperature)
    )
    summary = extract_text(response).strip()
    return summary


def build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Gemini-2.5-Flash ç‚ºæ¯å€‹ç« ç¯€ç”Ÿæˆæ¿ƒç¸®ç‰ˆæ‘˜è¦"
    )
    parser.add_argument("--config", default="./podcast_config.yaml",
                        help="é…ç½®æª”è·¯å¾‘ (é è¨­: ./podcast_config.yaml)")
    parser.add_argument("--book-id",
                        default=os.environ.get("STORY_BOOK_ID"),
                        help="è¦è™•ç†çš„æ›¸ç±è³‡æ–™å¤¾åç¨±ï¼ˆå¿…å¡«ï¼Œå¯ç”¨ STORY_BOOK_ID ç’°å¢ƒè®Šæ•¸ï¼‰")
    parser.add_argument("--ratio", type=float, default=8.0,
                        help="æ‘˜è¦å£“ç¸®æ¯”ï¼ˆåŸæ–‡/æ‘˜è¦å­—æ•¸ï¼‰ï¼Œé è¨­ 8")
    parser.add_argument("--min-summary-words", type=int, default=80,
                        help="æ¯ç¯‡æ‘˜è¦æœ€å°‘å­—æ•¸")
    parser.add_argument("--max-summary-words", type=int, default=400,
                        help="æ¯ç¯‡æ‘˜è¦æœ€å¤šå­—æ•¸")
    parser.add_argument("--force", action="store_true",
                        help="å¿½ç•¥ç¾æœ‰æ‘˜è¦ä¸¦é‡æ–°ç”Ÿæˆ")
    parser.add_argument("--model", default="gemini-2.5-flash",
                        help="è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹åç¨±")
    parser.add_argument("--workers", type=int, default=0,
                        help="åŒæ™‚é€å‡ºçš„è«‹æ±‚æ•¸ (0 è¡¨ç¤ºä¾ç« ç¯€æ•¸å…¨é–‹)")
    parser.add_argument("--temperature", type=float, default=0.2,
                        help="Gemini ç”Ÿæˆæ‘˜è¦æ™‚çš„ temperature")
    parser.add_argument("--start-chapter", type=int, default=1,
                        help="è¦è™•ç†çš„èµ·å§‹ç« ç¯€ï¼ˆ1-basedï¼Œå«ï¼‰ï¼Œé è¨­ 1")
    parser.add_argument("--end-chapter", type=int,
                        help="è¦è™•ç†çš„çµæŸç« ç¯€ï¼ˆ1-basedï¼Œå«ï¼‰ï¼Œé è¨­è™•ç†åˆ°æœ€å¾Œä¸€ç« ")
    parser.add_argument("--limit", type=int,
                        help="æœ€å¤šè™•ç†å¤šå°‘ç« ï¼ˆåœ¨å¥—ç”¨èµ·è¨–ç¯„åœå¾Œï¼‰")
    return parser


def _generate_summary_task(chapter: ChapterFile, summary_path: Path, target_words: int,
                           model: str, temperature: float) -> str:
    client = genai.Client(api_key=GEMINI_API_KEY)
    summary = summarize_chapter(client, model, chapter, target_words, temperature)
    summary_path.parent.mkdir(parents=True, exist_ok=True)
    summary_path.write_text(summary, encoding="utf-8")
    return summary


def main() -> None:
    parser = build_arg_parser()
    args = parser.parse_args()

    config = load_config(args.config)
    if not args.book_id:
        print("âŒ å¿…é ˆæŒ‡å®š --book-id æˆ–è¨­å®š STORY_BOOK_ID", file=sys.stderr)
        sys.exit(1)

    try:
        book_cfg = resolve_book_config(config, args.book_id)
    except Exception as exc:
        print(f"âŒ {exc}")
        sys.exit(1)

    summaries_dir = Path(book_cfg['summaries_dir'])
    summaries_dir.mkdir(parents=True, exist_ok=True)

    chapters = collect_chapter_files(book_cfg)
    start_chapter = max(1, args.start_chapter)
    end_chapter = args.end_chapter if args.end_chapter and args.end_chapter >= start_chapter else None

    chapters = [
        chapter for chapter in chapters
        if chapter.number >= start_chapter and (end_chapter is None or chapter.number <= end_chapter)
    ]

    if args.limit is not None and args.limit > 0:
        chapters = chapters[:args.limit]

    if not chapters:
        print("âš ï¸ ç¯„åœéæ¿¾å¾Œæ²’æœ‰éœ€è¦è™•ç†çš„ç« ç¯€ã€‚")
        return
    metadata: List[Dict[str, Any]] = []
    generated = 0
    skipped = 0
    start_time = time.time()
    pending_jobs: List[Tuple[ChapterFile, Path, int]] = []
    suffix = book_cfg.get('summary_suffix', '_summary.txt')

    for chapter in chapters:
        summary_path = summaries_dir / f"{chapter.path.stem}{suffix}"

        if summary_path.exists() and not args.force:
            skipped += 1
            metadata.append({
                "chapter": chapter.number,
                "file": str(chapter.path),
                "summary_file": str(summary_path),
                "word_count": chapter.word_count,
                "status": "existing"
            })
            continue

        target_words = int(max(
            args.min_summary_words,
            min(args.max_summary_words, round(chapter.word_count / args.ratio))
        ))
        pending_jobs.append((chapter, summary_path, target_words))

    workers = args.workers if args.workers > 0 else max(1, len(pending_jobs))

    if pending_jobs:
        print(f"ğŸš€ åŒæ­¥é€å‡º {len(pending_jobs)} ç« ç¯€æ‘˜è¦è«‹æ±‚ (workers={workers})")
        with ThreadPoolExecutor(max_workers=workers) as executor:
            future_map = {}
            for chapter, summary_path, target_words in pending_jobs:
                print(f"   â†³ æ’ç¨‹ ç« ç¯€ {chapter.number}: {chapter.path.name} â†’ ç›®æ¨™ {target_words} words")
                future = executor.submit(
                    _generate_summary_task,
                    chapter,
                    summary_path,
                    target_words,
                    args.model,
                    args.temperature,
                )
                future_map[future] = (chapter, summary_path, target_words)

            for future in as_completed(future_map):
                chapter, summary_path, target_words = future_map[future]
                try:
                    future.result()
                except Exception as exc:
                    print(f"âŒ ç« ç¯€ {chapter.number} ç”Ÿæˆå¤±æ•—: {exc}")
                    metadata.append({
                        "chapter": chapter.number,
                        "file": str(chapter.path),
                        "summary_file": str(summary_path),
                        "word_count": chapter.word_count,
                        "target_summary_words": target_words,
                        "status": f"error: {exc}"
                    })
                    continue

                generated += 1
                metadata.append({
                    "chapter": chapter.number,
                    "file": str(chapter.path),
                    "summary_file": str(summary_path),
                    "word_count": chapter.word_count,
                    "target_summary_words": target_words,
                    "status": "generated"
                })
                print(f"âœ… å·²ä¿å­˜: {summary_path}")

    meta_path = summaries_dir / "summaries_index.json"
    meta_payload = {
        "generated_at": datetime.utcnow().isoformat() + "Z",
        "book_id": book_cfg.get("book_id"),
        "chapters_dir": book_cfg['chapters_dir'],
        "model": args.model,
        "ratio": args.ratio,
        "min_summary_words": args.min_summary_words,
        "max_summary_words": args.max_summary_words,
        "workers": workers,
        "items": metadata
    }
    meta_path.write_text(json.dumps(meta_payload, ensure_ascii=False, indent=2), encoding="utf-8")

    duration = time.time() - start_time
    print("=" * 60)
    print("ğŸ“ æ¿ƒç¸®æ‘˜è¦å®Œæˆ")
    print(f"   â€¢ æ–°ç”Ÿæˆ: {generated}")
    print(f"   â€¢ å·²å­˜åœ¨è·³é: {skipped}")
    print(f"   â€¢ è¼¸å‡ºè³‡æ–™å¤¾: {summaries_dir}")
    print(f"   â€¢ èŠ±è²»æ™‚é–“: {duration:.1f} ç§’")
    print("=" * 60)


if __name__ == "__main__":
    main()
